{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from rouge_score import rouge_scorer\n",
    "from llm_unlearning.models.models import load_model_and_tokenizer\n",
    "from llm_unlearning.unlearning_datasets.hp import HPDataset\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def load_model_and_tokenizer_wrapper(model_path):\n",
    "    config = OmegaConf.create({\"path\": model_path, \"tokenizer_path\": \"microsoft/phi-1_5\", \"fp16\": True})\n",
    "    model, tokenizer = load_model_and_tokenizer(config)\n",
    "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_continuation(model, tokenizer, input_ids, attention_mask, max_new_tokens=100):\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return outputs[0]\n",
    "\n",
    "def sample_and_evaluate(hp_dataset, tokenizer, model, num_samples, prefix_length, batch_size=32, max_new_tokens=256):\n",
    "    rouge_scores = []\n",
    "\n",
    "    for i in tqdm(range(0, num_samples, batch_size)):\n",
    "        batch_size = min(batch_size, num_samples - i)\n",
    "\n",
    "        batch_items = [hp_dataset[torch.randint(len(hp_dataset), (1,)).item()] for _ in range(batch_size)]\n",
    "\n",
    "        input_ids = torch.stack([item['input_ids'] for item in batch_items]).to(model.device)\n",
    "        attention_mask = torch.stack([item['attention_mask'] for item in batch_items]).to(model.device)\n",
    "\n",
    "        prefix_input_ids = input_ids[:, :prefix_length]\n",
    "        prefix_attention_mask = attention_mask[:, :prefix_length]\n",
    "\n",
    "        continuations = model.generate(\n",
    "            input_ids=prefix_input_ids,\n",
    "            attention_mask=prefix_attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            generated_text = tokenizer.decode(continuations[j], skip_special_tokens=True)\n",
    "            ground_truth = tokenizer.decode(input_ids[j][prefix_length:], skip_special_tokens=True)\n",
    "            generated_continuation = generated_text[len(tokenizer.decode(prefix_input_ids[j], skip_special_tokens=True)):]\n",
    "\n",
    "            rouge_score = scorer.score(ground_truth, generated_continuation)['rougeL'].recall\n",
    "            rouge_scores.append(rouge_score)\n",
    "\n",
    "    return rouge_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/nfs/homedirs/gudm/development/new/results/10/hp/oth/checkpoint-176\"\n",
    "model_path = \"microsoft/phi-1_5\"\n",
    "model, tokenizer = load_model_and_tokenizer_wrapper(model_path)\n",
    "\n",
    "hp_config = OmegaConf.create({\n",
    "    \"file_path\": \"/nfs/homedirs/gudm/development/new/llm_unlearning/llm_unlearning/unlearning_datasets/data/Harry_Potter_first_book_preprocessed.txt\",\n",
    "    \"max_length\": 256\n",
    "})\n",
    "hp_dataset = HPDataset(tokenizer, hp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_samples = 128\n",
    "prefix_lengths = [8, 16, 32, 64, 128]\n",
    "for prefix_len in prefix_lengths:\n",
    "    rouge_scores = sample_and_evaluate(hp_dataset, tokenizer, model, num_samples, prefix_len, batch_size, max_new_tokens=256-prefix_len)\n",
    "    avg_score = sum(rouge_scores) / len(rouge_scores)\n",
    "    print(f\"Average ROUGE-L score for prefix length {prefix_len}: {avg_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
