tofu_base: &tofu_base
  path: "locuslab/TOFU"
  max_length: 512
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  question_key: "question"
  answer_key: "answer"
  perturbed_answer_key: "perturbed_answer"
  paraphrased_answer_key: "paraphrased_answer"
  perturb_probability: false

model:
  path: "/path/to/checkpoint-123" # Alternatively, path to directory with checkpoint directories
  tokenizer_path: "/path/to/checkpoint-123"
  # If base path is set, it's treated as checkpoint-0
  base_path: "locuslab/tofu_ft_phi-1.5"
  base_tokenizer_path: "microsoft/phi-1_5"
  # Retain model used to evaluate Forget Quality using the KS-test
  retain_path: "/path/to/retain_model"
  retain_tokenizer_path: "/path/to/retain_model"
  fp16: true

batch_size: 128
max_length: 200

evaluation_groups:
  - name: "forget_evaluation"
    datasets:
      tofu_forget:
        <<: *tofu_base
        name: "tofu_forget"
        split: "forget01_perturbed"
    metrics:
      - truth_ratio
    batch_size_factors:
      truth_ratio: 0.25
    aggregate_metrics:
      - ks_test
    save_results_path: "./forget_results.json"

  - name: "retain_evaluation"
    datasets:
      tofu_retain:
        <<: *tofu_base
        name: "tofu_retain"
        split: "retain_perturbed"
      real_authors:
        <<: *tofu_base
        name: "real_authors"
        split: "real_authors_perturbed"
        paraphrased_answer_key: "answer"
        perturb_probability: true
      world_facts:
        <<: *tofu_base
        name: "world_facts"
        split: "world_facts_perturbed"
        paraphrased_answer_key: "answer"
        perturb_probability: true
    metrics:
      - truth_ratio
      - probability
      - rouge_l
    batch_size_factors:
      truth_ratio: 0.25
    aggregate_metrics:
      - model_utility
    save_results_path: "./retain_results.json"

