tofu_base: &tofu_base
  path: "locuslab/TOFU"
  max_length: 512
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  question_key: "question"
  answer_key: "answer"
  perturbed_answer_key: "perturbed_answer"
  paraphrased_answer_key: "paraphrased_answer"
  perturb_probability: false

model:
  path: "/path/to/checkpoint-123" # Alternatively, path to directory with checkpoint directories
  tokenizer_path: "/path/to/checkpoint-123"
  # If base path is set, it's treated as checkpoint-0
  base_path: "locuslab/tofu_ft_phi-1.5"
  base_tokenizer_path: "microsoft/phi-1_5"
  # Retain model used to evaluate Forget Quality using the KS-test
  retain_path: "/path/to/retain_model"
  retain_tokenizer_path: "/path/to/retain_model"
  fp16: true

# If using a wrapper, set these:
# wrapper:
#   name: "logit_masking" # or "embedding_remapping"
#   kwargs:
#     strategy: "top_k_masking"
#     masking_percentage: 1.0

batch_size: 128
max_length: 200
delete_after_eval: false

evaluation_groups:
  - name: "forget_evaluation"
    datasets:
      tofu_forget:
        <<: *tofu_base
        name: "tofu_forget"
        split: "forget10_perturbed"
    metrics:
      - truth_ratio
      # You can pass config values like this:
      # - name: unlearning_coherency
      #   config:
      #     model_backend: openai
      #     openai_model: "gpt-4"
    batch_size_factors:
      truth_ratio: 0.25
    aggregate_metrics:
      - ks_test
    save_results_path: "./forget_results.json"

  - name: "retain_evaluation"
    datasets:
      tofu_retain:
        <<: *tofu_base
        name: "tofu_retain"
        split: "retain_perturbed"
      real_authors:
        <<: *tofu_base
        name: "real_authors"
        split: "real_authors_perturbed"
        paraphrased_answer_key: "answer"
        perturb_probability: true
      world_facts:
        <<: *tofu_base
        name: "world_facts"
        split: "world_facts_perturbed"
        paraphrased_answer_key: "answer"
        perturb_probability: true
    metrics:
      - truth_ratio
      - probability
      - rouge_l
    batch_size_factors:
      truth_ratio: 0.25
    aggregate_metrics:
      - model_utility
    save_results_path: "./retain_results.json"

